{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maple127/public127.github.io/blob/main/chapter_linear-classification/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e314f71f",
      "metadata": {
        "id": "e314f71f"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9b651465",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b651465",
        "outputId": "0c0a087a-44b2-456a-b989-78054c292e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.11/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (from d2l) (1.23.5)\n",
            "Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.11/dist-packages (from d2l) (3.7.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.11/dist-packages (from d2l) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.11/dist-packages (from d2l) (2.31.0)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.11/dist-packages (from d2l) (2.0.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (from d2l) (1.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.5.7)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (11.2.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l) (2.9.0.post0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l) (2025.6.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.19.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.8.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.3.1)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (4.24.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (4.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "651fef7a",
      "metadata": {
        "origin_pos": 1,
        "id": "651fef7a"
      },
      "source": [
        "# The Base Classification Model\n",
        ":label:`sec_classification`\n",
        "\n",
        "You may have noticed that the implementations from scratch and the concise implementation using framework functionality were quite similar in the case of regression. The same is true for classification. Since many models in this book deal with classification, it is worth adding functionalities to support this setting specifically. This section provides a base class for classification models to simplify future code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e1dd1359",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:28.524732Z",
          "iopub.status.busy": "2023-08-18T20:14:28.524009Z",
          "iopub.status.idle": "2023-08-18T20:14:31.450273Z",
          "shell.execute_reply": "2023-08-18T20:14:31.448972Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "e1dd1359"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70bc0d4e",
      "metadata": {
        "origin_pos": 6,
        "id": "70bc0d4e"
      },
      "source": [
        "## The `Classifier` Class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641cbe3d",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "641cbe3d"
      },
      "source": [
        "We define the `Classifier` class below. In the `validation_step` we report both the loss value and the classification accuracy on a validation batch. We draw an update for every `num_val_batches` batches. This has the benefit of generating the averaged loss and accuracy on the whole validation data. These average numbers are not exactly correct if the final batch contains fewer examples, but we ignore this minor difference to keep the code simple.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1bb74037",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:31.455489Z",
          "iopub.status.busy": "2023-08-18T20:14:31.454488Z",
          "iopub.status.idle": "2023-08-18T20:14:31.461017Z",
          "shell.execute_reply": "2023-08-18T20:14:31.460154Z"
        },
        "origin_pos": 9,
        "tab": [
          "pytorch"
        ],
        "id": "1bb74037"
      },
      "outputs": [],
      "source": [
        "class Classifier(d2l.Module):  #@save\n",
        "    \"\"\"The base class of classification models.\"\"\"\n",
        "    def validation_step(self, batch):\n",
        "        Y_hat = self(*batch[:-1])\n",
        "        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n",
        "        self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5244291",
      "metadata": {
        "origin_pos": 11,
        "id": "c5244291"
      },
      "source": [
        "By default we use a stochastic gradient descent optimizer, operating on minibatches, just as we did in the context of linear regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3d1c1bb6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:31.464177Z",
          "iopub.status.busy": "2023-08-18T20:14:31.463903Z",
          "iopub.status.idle": "2023-08-18T20:14:31.468562Z",
          "shell.execute_reply": "2023-08-18T20:14:31.467672Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "3d1c1bb6"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(d2l.Module)  #@save\n",
        "def configure_optimizers(self):\n",
        "    return torch.optim.SGD(self.parameters(), lr=self.lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28232a31",
      "metadata": {
        "origin_pos": 16,
        "id": "28232a31"
      },
      "source": [
        "## Accuracy\n",
        "\n",
        "Given the predicted probability distribution `y_hat`,\n",
        "we typically choose the class with the highest predicted probability\n",
        "whenever we must output a hard prediction.\n",
        "Indeed, many applications require that we make a choice.\n",
        "For instance, Gmail must categorize an email into \"Primary\", \"Social\", \"Updates\", \"Forums\", or \"Spam\".\n",
        "It might estimate probabilities internally,\n",
        "but at the end of the day it has to choose one among the classes.\n",
        "\n",
        "When predictions are consistent with the label class `y`, they are correct.\n",
        "The classification accuracy is the fraction of all predictions that are correct.\n",
        "Although it can be difficult to optimize accuracy directly (it is not differentiable),\n",
        "it is often the performance measure that we care about the most. It is often *the*\n",
        "relevant quantity in benchmarks. As such, we will nearly always report it when training classifiers.\n",
        "\n",
        "Accuracy is computed as follows.\n",
        "First, if `y_hat` is a matrix,\n",
        "we assume that the second dimension stores prediction scores for each class.\n",
        "We use `argmax` to obtain the predicted class by the index for the largest entry in each row.\n",
        "Then we [**compare the predicted class with the ground truth `y` elementwise.**]\n",
        "Since the equality operator `==` is sensitive to data types,\n",
        "we convert `y_hat`'s data type to match that of `y`.\n",
        "The result is a tensor containing entries of 0 (false) and 1 (true).\n",
        "Taking the sum yields the number of correct predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b132abd8",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "9"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T20:14:31.471739Z",
          "iopub.status.busy": "2023-08-18T20:14:31.471463Z",
          "iopub.status.idle": "2023-08-18T20:14:31.477124Z",
          "shell.execute_reply": "2023-08-18T20:14:31.476264Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "id": "b132abd8"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(Classifier)  #@save\n",
        "def accuracy(self, Y_hat, Y, averaged=True):\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
        "    preds = Y_hat.argmax(axis=1).type(Y.dtype)\n",
        "    compare = (preds == Y.reshape(-1)).type(torch.float32)\n",
        "    return compare.mean() if averaged else compare"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47696b41",
      "metadata": {
        "origin_pos": 20,
        "id": "47696b41"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Classification is a sufficiently common problem that it warrants its own convenience functions. Of central importance in classification is the *accuracy* of the classifier. Note that while we often care primarily about accuracy, we train classifiers to optimize a variety of other objectives for statistical and computational reasons. However, regardless of which loss function was minimized during training, it is useful to have a convenience method for assessing the accuracy of our classifier empirically.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Denote by $L_\\textrm{v}$ the validation loss, and let $L_\\textrm{v}^\\textrm{q}$ be its quick and dirty estimate computed by the loss function averaging in this section. Lastly, denote by $l_\\textrm{v}^\\textrm{b}$ the loss on the last minibatch. Express $L_\\textrm{v}$ in terms of $L_\\textrm{v}^\\textrm{q}$, $l_\\textrm{v}^\\textrm{b}$, and the sample and minibatch sizes.\n",
        "1. Show that the quick and dirty estimate $L_\\textrm{v}^\\textrm{q}$ is unbiased. That is, show that $E[L_\\textrm{v}] = E[L_\\textrm{v}^\\textrm{q}]$. Why would you still want to use $L_\\textrm{v}$ instead?\n",
        "1. Given a multiclass classification loss, denoting by $l(y,y')$ the penalty of estimating $y'$ when we see $y$ and given a probabilty $p(y \\mid x)$, formulate the rule for an optimal selection of $y'$. Hint: express the expected loss, using $l$ and $p(y \\mid x)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "V_aQEMIOhy9g"
      },
      "id": "V_aQEMIOhy9g"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 加载验证数据集\n",
        "val_dataset = datasets.FashionMNIST(root='~/Datasets', train=False, transform=transforms.ToTensor(), download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 随机模型\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(784, 10)\n",
        ")\n",
        "with torch.no_grad():\n",
        "    for param in model.parameters():\n",
        "        param.uniform_(-0.1, 0.1)\n",
        "\n",
        "# 定义验证损失函数\n",
        "def compute_losses(model, dataloader):\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "    quick_loss_sum = 0\n",
        "    num_batches = len(dataloader)\n",
        "    last_batch_loss = 0\n",
        "    last_batch_size = 0\n",
        "\n",
        "    for i, (X, y) in enumerate(dataloader):\n",
        "        with torch.no_grad():\n",
        "            y_hat = model(X)\n",
        "            loss = F.cross_entropy(y_hat, y, reduction='none')\n",
        "            batch_total = loss.sum().item()\n",
        "            batch_mean = loss.mean().item()\n",
        "            batch_size = y.shape[0]\n",
        "\n",
        "            total_loss += batch_total\n",
        "            total_samples += batch_size\n",
        "            quick_loss_sum += batch_mean\n",
        "\n",
        "            if i == num_batches - 1:\n",
        "                last_batch_loss = batch_mean\n",
        "                last_batch_size = batch_size\n",
        "\n",
        "    Lv = total_loss / total_samples\n",
        "    Lqv = quick_loss_sum / num_batches\n",
        "    return Lv, Lqv, last_batch_loss, last_batch_size, total_samples\n",
        "\n",
        "Lv, Lqv, lbv, B_last, N = compute_losses(model, val_loader)\n",
        "\n",
        "# 近似表达式重建 Lv\n",
        "Lv_estimate = ((N - B_last) / N) * Lqv + (B_last / N) * lbv\n",
        "\n",
        "print(f\"精确验证损失 Lv: {Lv:.4f}\")\n",
        "print(f\"快速估计 Lqv:     {Lqv:.4f}\")\n",
        "print(f\"最后一批损失 lbv: {lbv:.4f}\")\n",
        "print(f\"表达式估计 Lv:    {Lv_estimate:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JOYcTtkiCuC",
        "outputId": "86647a82-fedf-42fb-f175-c7ad461a1cc3"
      },
      "id": "2JOYcTtkiCuC",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 21.1MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 343kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 6.28MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 18.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "精确验证损失 Lv: 2.3577\n",
            "快速估计 Lqv:     2.3572\n",
            "最后一批损失 lbv: 2.2662\n",
            "表达式估计 Lv:    2.3571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "WNuTbkTJh0Jh"
      },
      "id": "WNuTbkTJh0Jh"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def run_multiple_trials(num_trials=50):\n",
        "    Lv_list, Lqv_list = [], []\n",
        "    for _ in range(num_trials):\n",
        "        # 模型重新初始化\n",
        "        for param in model.parameters():\n",
        "            param.data.uniform_(-0.1, 0.1)\n",
        "        Lv, Lqv, _, _, _ = compute_losses(model, val_loader)\n",
        "        Lv_list.append(Lv)\n",
        "        Lqv_list.append(Lqv)\n",
        "    return np.mean(Lv_list), np.mean(Lqv_list)\n",
        "\n",
        "mean_Lv, mean_Lqv = run_multiple_trials()\n",
        "print(f\"多次运行期望 E[Lv]:  {mean_Lv:.4f}\")\n",
        "print(f\"多次运行期望 E[Lqv]: {mean_Lqv:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-o3ldiViIFu",
        "outputId": "9c458e6d-ace3-498b-f055-262e00ded72d"
      },
      "id": "H-o3ldiViIFu",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "多次运行期望 E[Lv]:  2.5504\n",
            "多次运行期望 E[Lqv]: 2.5501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "qHFU4DV4h06V"
      },
      "id": "qHFU4DV4h06V"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 示例：类别数\n",
        "num_classes = 5\n",
        "\n",
        "# 定义损失矩阵 l(y, y')\n",
        "# 示例：当 y ≠ y' 时惩罚为 1；对角线为 0\n",
        "loss_matrix = torch.ones((num_classes, num_classes)) - torch.eye(num_classes)\n",
        "\n",
        "# 模拟一组概率分布 p(y|x)，形状：[num_classes]\n",
        "p_y_given_x = torch.tensor([0.1, 0.2, 0.3, 0.25, 0.15])\n",
        "\n",
        "# 计算每个可能的 y' 的期望损失\n",
        "expected_losses = torch.mv(loss_matrix.t(), p_y_given_x)\n",
        "\n",
        "# 选择使期望损失最小的 y'\n",
        "y_star = torch.argmin(expected_losses).item()\n",
        "\n",
        "print(\"每个预测类别的期望损失：\", expected_losses)\n",
        "print(\"最优选择 y* =\", y_star)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWalkxeCiJ7c",
        "outputId": "e7c2ba61-74a5-4d1e-eee4-51167b5a15ff"
      },
      "id": "CWalkxeCiJ7c",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "每个预测类别的期望损失： tensor([0.9000, 0.8000, 0.7000, 0.7500, 0.8500])\n",
            "最优选择 y* = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398f847c",
      "metadata": {
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "398f847c"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/6809)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}